{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_boston()\n",
    "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "y = pd.DataFrame(data.target, columns = ['target'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934924"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = scale(X)\n",
    "scaled_X = pd.DataFrame(scaled, columns=X.columns)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(linreg, scaled_X, y, scoring= 'r2', cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "combs = list(combinations(data.feature_names, 2))\n",
    "interactions = []\n",
    "copy_X = scaled_X.copy()\n",
    "\n",
    "for comb in combs:\n",
    "    copy_X['interaction'] = copy_X[comb[0]] * copy_X[comb[1]]\n",
    "    r2 = np.mean(cross_val_score(linreg, copy_X, y, cv=crossvalidation))\n",
    "    if r2 > baseline:\n",
    "        interactions.append((comb[0], comb[1], round(r2, 3)))\n",
    "interactions = sorted(interactions, key=lambda x: x[2], reverse=True)[:7]\n",
    "print(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>32.74350</td>\n",
       "      <td>1946.200</td>\n",
       "      <td>6.575</td>\n",
       "      <td>100.5975</td>\n",
       "      <td>15.18825</td>\n",
       "      <td>3.537350</td>\n",
       "      <td>428.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>58.68794</td>\n",
       "      <td>1553.882</td>\n",
       "      <td>12.842</td>\n",
       "      <td>114.2938</td>\n",
       "      <td>45.39647</td>\n",
       "      <td>3.011449</td>\n",
       "      <td>506.6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>28.95555</td>\n",
       "      <td>1738.770</td>\n",
       "      <td>14.370</td>\n",
       "      <td>127.8930</td>\n",
       "      <td>50.79795</td>\n",
       "      <td>3.369765</td>\n",
       "      <td>439.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>20.57412</td>\n",
       "      <td>1553.556</td>\n",
       "      <td>20.994</td>\n",
       "      <td>130.8626</td>\n",
       "      <td>15.25564</td>\n",
       "      <td>3.205084</td>\n",
       "      <td>320.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>38.09351</td>\n",
       "      <td>1586.634</td>\n",
       "      <td>21.441</td>\n",
       "      <td>133.6489</td>\n",
       "      <td>15.58046</td>\n",
       "      <td>3.273326</td>\n",
       "      <td>387.3674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  32.74350   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  58.68794   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  28.95555   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  20.57412   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  38.09351   \n",
       "\n",
       "     RM_TAX  RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0  1946.200   6.575    100.5975  15.18825  3.537350  428.6900  \n",
       "1  1553.882  12.842    114.2938  45.39647  3.011449  506.6169  \n",
       "2  1738.770  14.370    127.8930  50.79795  3.369765  439.0035  \n",
       "3  1553.556  20.994    130.8626  15.25564  3.205084  320.5084  \n",
       "4  1586.634  21.441    133.6489  15.58046  3.273326  387.3674  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter = scaled_X.copy()\n",
    "for inter in interactions:\n",
    "    df_inter[inter[0] + '_' + inter[1]] = X[inter[0]] * X[inter[1]]\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RM', 4, 0.8),\n",
       " ('RM', 2, 0.782),\n",
       " ('LSTAT', 4, 0.782),\n",
       " ('RM', 3, 0.781),\n",
       " ('LSTAT', 3, 0.774),\n",
       " ('LSTAT', 2, 0.772),\n",
       " ('DIS', 3, 0.737),\n",
       " ('DIS', 2, 0.732),\n",
       " ('DIS', 4, 0.731),\n",
       " ('TAX', 4, 0.724),\n",
       " ('ZN', 3, 0.723),\n",
       " ('INDUS', 2, 0.723),\n",
       " ('INDUS', 3, 0.723),\n",
       " ('INDUS', 4, 0.723),\n",
       " ('AGE', 3, 0.722),\n",
       " ('AGE', 4, 0.722),\n",
       " ('NOX', 4, 0.721),\n",
       " ('AGE', 2, 0.721),\n",
       " ('TAX', 3, 0.721),\n",
       " ('PTRATIO', 2, 0.721),\n",
       " ('ZN', 2, 0.72),\n",
       " ('ZN', 4, 0.72),\n",
       " ('RAD', 4, 0.72),\n",
       " ('B', 2, 0.72),\n",
       " ('TAX', 2, 0.719),\n",
       " ('PTRATIO', 3, 0.719),\n",
       " ('B', 3, 0.719),\n",
       " ('CHAS', 2, 0.718),\n",
       " ('NOX', 2, 0.718),\n",
       " ('NOX', 3, 0.718),\n",
       " ('B', 4, 0.718)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "degrees = [2,3,4]\n",
    "polys = []\n",
    "\n",
    "for col in scaled_X.columns:\n",
    "    for degree in degrees:\n",
    "        copy_X = X.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        new_X = poly.fit_transform(copy_X[[col]])\n",
    "        copy_X = pd.concat([copy_X.drop(col, axis=1), pd.DataFrame(new_X)], axis=1)\n",
    "        r2 = np.mean(cross_val_score(linreg, copy_X, y, cv=crossvalidation))\n",
    "        if r2 > baseline:\n",
    "            polys.append((col, degree, round(r2, 3)))\n",
    "polys = sorted(polys, key= lambda x: x[2], reverse=True)\n",
    "polys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>4</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>4</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>4</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>4</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>4</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>4</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>4</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>4</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>3</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>4</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>4</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>2</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2\n",
       "0                \n",
       "RM       4  0.800\n",
       "LSTAT    4  0.782\n",
       "DIS      4  0.737\n",
       "TAX      4  0.724\n",
       "ZN       4  0.723\n",
       "INDUS    4  0.723\n",
       "AGE      4  0.722\n",
       "NOX      4  0.721\n",
       "PTRATIO  3  0.721\n",
       "RAD      4  0.720\n",
       "B        4  0.720\n",
       "CHAS     2  0.718"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomials = pd.DataFrame(polys)\n",
    "polynomials.groupby([0], sort=False).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>4</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>3</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1      2\n",
       "0     RM  4  0.800\n",
       "1     RM  2  0.782\n",
       "2  LSTAT  4  0.782\n",
       "3     RM  3  0.781\n",
       "4  LSTAT  3  0.774"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomials.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['RM', 'LSTAT']:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    new_X = poly.fit_transform(X[[col]])\n",
    "    colnames= [col, col + '_' + '2',  col + '_' + '3', col + '_' + '4']\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1), pd.DataFrame(new_X, columns=colnames)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.537350</td>\n",
       "      <td>428.6900</td>\n",
       "      <td>6.575</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>284.241359</td>\n",
       "      <td>1868.886938</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.8004</td>\n",
       "      <td>123.505992</td>\n",
       "      <td>615.059840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>3.011449</td>\n",
       "      <td>506.6169</td>\n",
       "      <td>6.421</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>264.732956</td>\n",
       "      <td>1699.850313</td>\n",
       "      <td>9.14</td>\n",
       "      <td>83.5396</td>\n",
       "      <td>763.551944</td>\n",
       "      <td>6978.864768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>3.369765</td>\n",
       "      <td>439.0035</td>\n",
       "      <td>7.185</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>370.920057</td>\n",
       "      <td>2665.060607</td>\n",
       "      <td>4.03</td>\n",
       "      <td>16.2409</td>\n",
       "      <td>65.450827</td>\n",
       "      <td>263.766833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>3.205084</td>\n",
       "      <td>320.5084</td>\n",
       "      <td>6.998</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>342.706084</td>\n",
       "      <td>2398.257176</td>\n",
       "      <td>2.94</td>\n",
       "      <td>8.6436</td>\n",
       "      <td>25.412184</td>\n",
       "      <td>74.711821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>3.273326</td>\n",
       "      <td>387.3674</td>\n",
       "      <td>7.147</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>365.065966</td>\n",
       "      <td>2609.126456</td>\n",
       "      <td>5.33</td>\n",
       "      <td>28.4089</td>\n",
       "      <td>151.419437</td>\n",
       "      <td>807.065599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO     ...         NOX_RM    RM_AGE     RM  \\\n",
       "0 -0.982843 -0.666608 -1.459000     ...       3.537350  428.6900  6.575   \n",
       "1 -0.867883 -0.987329 -0.303094     ...       3.011449  506.6169  6.421   \n",
       "2 -0.867883 -0.987329 -0.303094     ...       3.369765  439.0035  7.185   \n",
       "3 -0.752922 -1.106115  0.113032     ...       3.205084  320.5084  6.998   \n",
       "4 -0.752922 -1.106115  0.113032     ...       3.273326  387.3674  7.147   \n",
       "\n",
       "        RM_2        RM_3         RM_4  LSTAT  LSTAT_2     LSTAT_3      LSTAT_4  \n",
       "0  43.230625  284.241359  1868.886938   4.98  24.8004  123.505992   615.059840  \n",
       "1  41.229241  264.732956  1699.850313   9.14  83.5396  763.551944  6978.864768  \n",
       "2  51.624225  370.920057  2665.060607   4.03  16.2409   65.450827   263.766833  \n",
       "3  48.972004  342.706084  2398.257176   2.94   8.6436   25.412184    74.711821  \n",
       "4  51.079609  365.065966  2609.126456   5.33  28.4089  151.419437   807.065599  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061549447223216"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = np.mean(cross_val_score(linreg, df_inter, y, scoring='r2', cv=crossvalidation))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7168057552393374\n",
      "Training MSE: 22.4779838218779\n",
      "Test r^2: 0.7789410172622855\n",
      "Test MSE: 21.89776539604951\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, random_state=1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Test r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8155720603121368\n",
      "Training MSE: 14.638603436696354\n",
      "Test r^2: 0.8648860563031306\n",
      "Test MSE: 13.38418101887117\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha= model_aic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.807489057780076\n",
      "Training MSE: 15.280175797396733\n",
      "Test r^2: 0.8775992537339209\n",
      "Test MSE: 12.124831087348989\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha= model_bic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
